{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy Primer - 3\n",
    "- Importing datasets\n",
    "    - loadtxt\n",
    "    - genfromtxt\n",
    "- Processing data\n",
    "    - Splitting data\n",
    "- Summarizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Datasets\n",
    "- Datasets in text files (```.txt, .csv```, etc.) can be imported using ```loadtxt()``` for ```genfromtxt()```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loadtxt()\n",
    "- ```loadtxt()``` is used when there do not exist missing values\n",
    "- Hence, number of values in each row should be equal\n",
    "- Key parameters\n",
    "    - ```fname```: designates name of text file to be imported\n",
    "    - ```dtype```: data type of array to be created as result (default: ```float```)\n",
    "    - ```delimiter```: string used to separate values (default: whitespace)\n",
    "    - ```skiprows```: skip first *n* rows (default: 0)\n",
    "    - ```usecols```: column indices to be read (default: ```None``` => all cols are used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.   4.   6.   8.  10.]\n",
      " [ 12.  14.  16.  18.  20.]\n",
      " [ 22.  24.  26.  28.  30.]\n",
      " [ 32.  34.  36.  38.  40.]\n",
      " [ 42.  44.  46.  48.  50.]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# importing dataset with default settings\n",
    "data = np.loadtxt('even_numbers.txt')\n",
    "print(data)\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14 18]\n",
      " [24 28]\n",
      " [34 38]\n",
      " [44 48]]\n"
     ]
    }
   ],
   "source": [
    "# importing dataset with parameter settings\n",
    "# skiprows is especially useful when you want to get rid of \"header\" of dataset \n",
    "data = np.loadtxt('even_numbers.txt', dtype = int, skiprows = 1, usecols = (1,3))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2' '12' '22' '32' '42']\n"
     ]
    }
   ],
   "source": [
    "# importing dataset with parameter settings\n",
    "data = np.loadtxt('even_numbers.txt', dtype = np.str_, usecols = 0)\n",
    "print(data)        # note that resulting array is 1-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214, 11)\n",
      "float64\n",
      "[[  1.52101  13.64      4.49    ...,   0.        0.        1.     ]\n",
      " [  1.51761  13.89      3.6     ...,   0.        0.        1.     ]\n",
      " [  1.51618  13.53      3.55    ...,   0.        0.        1.     ]\n",
      " ..., \n",
      " [  1.52065  14.36      0.      ...,   1.64      0.        7.     ]\n",
      " [  1.51651  14.38      0.      ...,   1.57      0.        7.     ]\n",
      " [  1.51711  14.23      0.      ...,   1.67      0.        7.     ]]\n"
     ]
    }
   ],
   "source": [
    "# .csv files could be imported as well\n",
    "# in this case, delimiter should be set to ','\n",
    "data = np.loadtxt('glass.csv', delimiter = ',')\n",
    "print(data.shape)        # dataset with 214 rows & 11 columns\n",
    "print(data.dtype)        # dtype is float64 as default\n",
    "data = data[:, 1:]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### genfromtxt()\n",
    "- ```genfromtxt()``` is used when dataset has some missing values\n",
    "- Otherwise, it is largely identical to ```loadtxt()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   3.   5.   7.   9.]\n",
      " [ 11.  13.  15.  17.  19.]\n",
      " [ 21.  23.  25.  27.  29.]\n",
      " [ 31.  33.  35.  37.  39.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Buomsoo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: ConversionWarning: Some errors were detected !\n",
      "    Line #5 (got 4 columns instead of 5)\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# when ' '(whitespace) is used as delimiter\n",
    "data = np.genfromtxt('odd_numbers.txt', invalid_raise = False)\n",
    "print(data)      # you can see that last row is removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   3.   5.   7.   9.]\n",
      " [ 11.  13.  15.  17.  19.]\n",
      " [ 21.  23.  25.  27.  29.]\n",
      " [ 31.  33.  35.  37.  39.]\n",
      " [ 43.  45.  47.  49.  nan]]\n"
     ]
    }
   ],
   "source": [
    "# when ',' is used as delimiter\n",
    "data = np.genfromtxt('odd_numbers.csv', delimiter = ',')\n",
    "print(data)      # you could see that last element is set to nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   3.   5.   7.   9.]\n",
      " [ 11.  13.  15.  17.  19.]\n",
      " [ 21.  23.  25.  27.  29.]\n",
      " [ 31.  33.  35.  37.  39.]\n",
      " [ 43.  45.  47.  49.   0.]]\n"
     ]
    }
   ],
   "source": [
    "# value to fill missing element can be deisgnated\n",
    "data = np.genfromtxt('odd_numbers.csv', delimiter = ',', filling_values = 0)\n",
    "print(data)       # fill missing value with 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   3.   5.   7.   9.]\n",
      " [ 11.  13.  15.  17.  19.]\n",
      " [ 21.  23.  25.  27.  29.]\n",
      " [ 31.  33.  35.  37.  39.]\n",
      " [ 43.  45.  47.  49.  99.]]\n"
     ]
    }
   ],
   "source": [
    "# if there is certain string to designate missing value ('?' here)\n",
    "data = np.genfromtxt('odd_numbers_2.csv', delimiter = ',', missing_values = '?', \\\n",
    "                     filling_values = 99)\n",
    "print(data)       # fill missing value with 99."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3-1.\n",
    "- Import ```highway.csv``` using genfromtxt()\n",
    "    - Set ```dtype``` as string\n",
    "    - Replace missing values (```'?'```) with ```'Unknown'```\n",
    "    - Print first three rows of resulting array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['E1' 'M' '3' '1818' 'HIGHWAY' '?' '2' 'N' 'THROUGH' 'WOOD' 'SHORT' 'S'\n",
      "  'WOOD']\n",
      " ['E2' 'A' '25' '1819' 'HIGHWAY' '1037' '2' 'N' 'THROUGH' 'WOOD' 'SHORT'\n",
      "  'S' 'WOOD']\n",
      " ['E3' 'A' '39' '1829' 'AQUEDUCT' '?' '1' 'N' 'THROUGH' 'WOOD' '?' 'S'\n",
      "  'WOOD']]\n",
      "[['E1' 'M' '3' '1818' 'HIGHWAY' 'Unknown' '2' 'N' 'THROUGH' 'WOOD' 'SHORT'\n",
      "  'S' 'WOOD']\n",
      " ['E2' 'A' '25' '1819' 'HIGHWAY' '1037' '2' 'N' 'THROUGH' 'WOOD' 'SHORT'\n",
      "  'S' 'WOOD']\n",
      " ['E3' 'A' '39' '1829' 'AQUEDUCT' 'Unknown' '1' 'N' 'THROUGH' 'WOOD'\n",
      "  'Unknown' 'S' 'WOOD']]\n"
     ]
    }
   ],
   "source": [
    "### Your answer\n",
    "data = np.genfromtxt('highway.csv', delimiter = ',', dtype = np.str_, missing_values = \"?\", \\\n",
    "                    filling_values = 'Unknown')\n",
    "print(data[:3])\n",
    "\n",
    "data = np.loadtxt('highway.csv', delimiter = ',', dtype = np.str_)\n",
    "data[data == '?'] = 'Unknown'\n",
    "print(data[:3, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Processing data\n",
    "- Processing imported dataset is essential task in data mining\n",
    "- Many techniques we have learnt so far are used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data\n",
    "- In most cases, dataset is splitted into ```X data``` (input variables) and ```Y data``` (output variables), or other variable splits\n",
    "    - Then, dataset is splitted *column-wise*\n",
    "- Then, dataset is splitted into ```training data``` and ```validation/test data```, or cross-validated\n",
    "    - Then, dataset is splitted *row-wise*\n",
    "- In either case, array indexing & slicing are utilized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**glass dataset**\n",
    "- source: https://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.names\n",
    "- Number of instances (# rows): 214\n",
    "- Number of attributes (# columns): 10\n",
    "    - ID number: 1 to 214\n",
    "    - RI: refractive index\n",
    "    - Na: Sodium (unit measurement: weight percent in corresponding oxide, as are attributes 4-10)\n",
    "    - Mg: Magnesium\n",
    "    - Al: Aluminum\n",
    "    - Si: Silicon\n",
    "    - K: Potassium\n",
    "    - Ca: Calcium\n",
    "    - Ba: Barium\n",
    "    - Fe: Iron\n",
    "    - Type of glass: (class attribute)\n",
    "        - 1: building_windows_float_processed\n",
    "        - 2: building_windows_non_float_processed\n",
    "        - 3: vehicle_windows_float_processed\n",
    "        - 4: vehicle_windows_non_float_processed (none in this database)\n",
    "        - 5: containers\n",
    "        - 6: tableware\n",
    "        - 7: headlamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214, 11)\n",
      "[  1.00000000e+00   1.52101000e+00   1.36400000e+01   4.49000000e+00\n",
      "   1.10000000e+00   7.17800000e+01   6.00000000e-02   8.75000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# import dataset\n",
    "data = np.loadtxt('glass.csv', delimiter = ',')\n",
    "print(data.shape)\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214, 10)\n"
     ]
    }
   ],
   "source": [
    "# excluding ID number variable\n",
    "data_1 = data[:, 1:]\n",
    "print(data_1.shape)        # 10 columns now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214, 9)\n"
     ]
    }
   ],
   "source": [
    "# selecting only X data (excluding ID number & Type of glass variables)\n",
    "X_data = data[:, 1:-1]\n",
    "print(X_data.shape)        # 9 columns now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214, 3)\n"
     ]
    }
   ],
   "source": [
    "# selecting only RI, Na, Mg variables\n",
    "X_partial = data[:, 1:4]\n",
    "print(X_partial.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214,)\n"
     ]
    }
   ],
   "source": [
    "# selecting only Y data\n",
    "Y_data = data[:, -1]\n",
    "print(Y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 9)\n",
      "(64, 9)\n",
      "(150,)\n",
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "# splitting data into train-test set\n",
    "# first 150 data instances into train set, others into test set\n",
    "X_train = X_data[:150,:]\n",
    "X_test = X_data[150:, :]\n",
    "Y_train = Y_data[:150]\n",
    "Y_test = Y_data[150:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 9)\n",
      "(64, 9)\n",
      "(150,)\n",
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "# randomly performing train-test split\n",
    "data_shulffled = data               # copy data\n",
    "np.random.shuffle(data_shulffled)   # shulffle dataset randomly\n",
    "\n",
    "X_data = data_shulffled[:, 1:-1]\n",
    "Y_data = data_shulffled[:, -1]\n",
    "\n",
    "X_train = X_data[:150,:]\n",
    "X_test = X_data[150:, :]\n",
    "Y_train = Y_data[:150]\n",
    "Y_test = Y_data[150:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3-2.\n",
    "- Import ```dermatology.csv``` using ```genfromtxt()``` function\n",
    "    - Replace missing values ('?') with 0\n",
    "- Assign data in first 34 columns into X_data\n",
    "- Assign data in last column into Y_data\n",
    "- Perform train-test split\n",
    "    - Randomly assign half into train set, another half into test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2' '2' '0' '3' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '3' '2' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '3' '0' '0' '0' '1' '0' '55' '2']\n",
      "[ 2  2  0  3  0  0  0  0  1  0  0  0  0  0  0  3  2  0  0  0  0  0  0  0  0\n",
      "  0  0  3  0  0  0  1  0 55  2]\n",
      "(366, 35)\n",
      "(183, 34)\n",
      "(183, 34)\n",
      "(183,)\n",
      "(183,)\n"
     ]
    }
   ],
   "source": [
    "## Your answer\n",
    "data = np.loadtxt('dermatology.csv', delimiter = ',', dtype = np.str_)\n",
    "data[data == '?'] = 0\n",
    "print(data[0])\n",
    "data = np.array(data, dtype = np.int32)\n",
    "print(data[0])\n",
    "print(data.shape)\n",
    "\n",
    "np.random.shuffle(data)\n",
    "X_data = data[:, :34]\n",
    "y_data = data[:, -1]\n",
    "\n",
    "num_train = len(data)//2\n",
    "X_train = X_data[:num_train, :]\n",
    "X_test = X_data[num_train:, :]\n",
    "Y_train = y_data[:num_train]\n",
    "Y_test = y_data[num_train:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
